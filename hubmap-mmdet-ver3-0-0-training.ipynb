{"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"I couldn't find a notebook using the new mmdet version 3.0.0, so I made one myself. Please let me know if there are any mistakes!\n\nthe annotation josn file is from [this great notebook](https://www.kaggle.com/code/ammarnassanalhajali/hubmap-2023-k-fold-cv-coco-dataset-generator).\n\ninference notebook is [here](https://www.kaggle.com/code/andtaichi/hubmap-mmdet-ver3-0-0-infer/notebook).","metadata":{}},{"cell_type":"code","source":"# !pip install -U -qqq openmim\n# !mim install -qqq mmengine\n# !mim install -qqq \"mmcv>=2.0.0\"\n# !mim install -qqq mmdet\n# !pip install -U -qqq wandb","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bMYDFqlgSpr7","outputId":"47c74ceb-c957-4de7-e00c-1fb209570236","execution":{"iopub.status.busy":"2023-06-28T12:41:15.467837Z","iopub.execute_input":"2023-06-28T12:41:15.468219Z","iopub.status.idle":"2023-06-28T12:41:15.473403Z","shell.execute_reply.started":"2023-06-28T12:41:15.468180Z","shell.execute_reply":"2023-06-28T12:41:15.472492Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip install -qqq /kaggle/input/mmdet3-wheels-ando/addict-2.4.0-py3-none-any.whl\n!pip install -qqq /kaggle/input/mmdet3-wheels-ando/mmengine-0.7.3-py3-none-any.whl\n!pip install -qqq /kaggle/input/mmdet3-wheels-ando/mmcv-2.0.0-cp310-cp310-linux_x86_64.whl\n!pip install -qqq /kaggle/input/pycocotools-206/wheels/pycocotools-2.0.6-cp310-cp310-linux_x86_64.whl\n!pip install -qqq /kaggle/input/mmdet3-wheels-ando/terminaltables-3.1.10-py2.py3-none-any.whl\n!pip install -qqq /kaggle/input/mmdet3-wheels-ando/mmdet-3.0.0-py3-none-any.whl","metadata":{"execution":{"iopub.status.busy":"2023-06-28T12:41:15.475193Z","iopub.execute_input":"2023-06-28T12:41:15.475784Z","iopub.status.idle":"2023-06-28T12:42:40.620156Z","shell.execute_reply.started":"2023-06-28T12:41:15.475752Z","shell.execute_reply":"2023-06-28T12:42:40.618773Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value = user_secrets.get_secret(\"wandb-api\")\n\nimport wandb\nwandb.login(key=secret_value)","metadata":{"execution":{"iopub.status.busy":"2023-06-28T12:42:40.622758Z","iopub.execute_input":"2023-06-28T12:42:40.623139Z","iopub.status.idle":"2023-06-28T12:42:44.639131Z","shell.execute_reply.started":"2023-06-28T12:42:40.623101Z","shell.execute_reply":"2023-06-28T12:42:44.638093Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"import mmdet, mmcv\nprint(mmdet.__version__)\nprint(mmcv.__version__)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-V-93RXwT5UW","outputId":"74770888-ad8e-4148-cdd7-97ddd0aadc6f","execution":{"iopub.status.busy":"2023-06-28T12:42:44.640887Z","iopub.execute_input":"2023-06-28T12:42:44.641575Z","iopub.status.idle":"2023-06-28T12:42:48.337017Z","shell.execute_reply.started":"2023-06-28T12:42:44.641538Z","shell.execute_reply":"2023-06-28T12:42:48.336075Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"3.0.0\n2.0.0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Make config file","metadata":{"id":"uK78Si0e831C"}},{"cell_type":"code","source":"%mkdir /kaggle/working/configs/","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nZ5XYaL1B9vq","outputId":"59f10eed-a1c5-4fc2-8ab4-a2b80620d223","execution":{"iopub.status.busy":"2023-06-28T12:42:48.339409Z","iopub.execute_input":"2023-06-28T12:42:48.340822Z","iopub.status.idle":"2023-06-28T12:42:49.318663Z","shell.execute_reply.started":"2023-06-28T12:42:48.340786Z","shell.execute_reply":"2023-06-28T12:42:49.317228Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"%%writefile /kaggle/working/configs/custom_config.py\n\n# model settings\nmodel = dict(\n    type='MaskRCNN',  # The name of detector\n    data_preprocessor=dict(  # The config of data preprocessor, usually includes image normalization and padding\n        type='DetDataPreprocessor',  # The type of the data preprocessor, refer to https://mmdetection.readthedocs.io/en/latest/api.html#mmdet.models.data_preprocessors.DetDataPreprocessor\n        mean=[123.675, 116.28, 103.53],  # Mean values used to pre-training the pre-trained backbone models, ordered in R, G, B\n        std=[58.395, 57.12, 57.375],  # Standard variance used to pre-training the pre-trained backbone models, ordered in R, G, B\n        bgr_to_rgb=True,  # whether to convert image from BGR to RGB\n        pad_mask=True,  # whether to pad instance masks\n        pad_size_divisor=32),  # The size of padded image should be divisible by ``pad_size_divisor``\n    backbone=dict(  # The config of backbone\n        type='ResNet',  # The type of backbone network. Refer to https://mmdetection.readthedocs.io/en/latest/api.html#mmdet.models.backbones.ResNet\n        depth=50,  # The depth of backbone, usually it is 50 or 101 for ResNet and ResNext backbones.\n        num_stages=4,  # Number of stages of the backbone.\n        out_indices=(0, 1, 2, 3),  # The index of output feature maps produced in each stage\n        frozen_stages=1,  # The weights in the first stage are frozen\n        norm_cfg=dict(  # The config of normalization layers.\n            type='BN',  # Type of norm layer, usually it is BN or GN\n            requires_grad=True),  # Whether to train the gamma and beta in BN\n        norm_eval=True,  # Whether to freeze the statistics in BN\n        style='pytorch', # The style of backbone, 'pytorch' means that stride 2 layers are in 3x3 Conv, 'caffe' means stride 2 layers are in 1x1 Convs.\n    \tinit_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet50')),  # The ImageNet pretrained backbone to be loaded\n    neck=dict(\n        type='FPN',  # The neck of detector is FPN. We also support 'NASFPN', 'PAFPN', etc. Refer to https://mmdetection.readthedocs.io/en/latest/api.html#mmdet.models.necks.FPN for more details.\n        in_channels=[256, 512, 1024, 2048],  # The input channels, this is consistent with the output channels of backbone\n        out_channels=256,  # The output channels of each level of the pyramid feature map\n        num_outs=5),  # The number of output scales\n    rpn_head=dict(\n        type='RPNHead',  # The type of RPN head is 'RPNHead', we also support 'GARPNHead', etc. Refer to https://mmdetection.readthedocs.io/en/latest/api.html#mmdet.models.dense_heads.RPNHead for more details.\n        in_channels=256,  # The input channels of each input feature map, this is consistent with the output channels of neck\n        feat_channels=256,  # Feature channels of convolutional layers in the head.\n        anchor_generator=dict(  # The config of anchor generator\n            type='AnchorGenerator',  # Most of methods use AnchorGenerator, SSD Detectors uses `SSDAnchorGenerator`. Refer to https://github.com/open-mmlab/mmdetection/blob/main/mmdet/models/task_modules/prior_generators/anchor_generator.py#L18 for more details\n            scales=[8],  # Basic scale of the anchor, the area of the anchor in one position of a feature map will be scale * base_sizes\n            ratios=[0.5, 1.0, 2.0],  # The ratio between height and width.\n            strides=[4, 8, 16, 32, 64]),  # The strides of the anchor generator. This is consistent with the FPN feature strides. The strides will be taken as base_sizes if base_sizes is not set.\n        bbox_coder=dict(  # Config of box coder to encode and decode the boxes during training and testing\n            type='DeltaXYWHBBoxCoder',  # Type of box coder. 'DeltaXYWHBBoxCoder' is applied for most of the methods. Refer to https://github.com/open-mmlab/mmdetection/blob/main/mmdet/models/task_modules/coders/delta_xywh_bbox_coder.py#L13 for more details.\n            target_means=[0.0, 0.0, 0.0, 0.0],  # The target means used to encode and decode boxes\n            target_stds=[1.0, 1.0, 1.0, 1.0]),  # The standard variance used to encode and decode boxes\n        loss_cls=dict(  # Config of loss function for the classification branch\n            type='CrossEntropyLoss',  # Type of loss for classification branch, we also support FocalLoss etc. Refer to https://github.com/open-mmlab/mmdetection/blob/main/mmdet/models/losses/cross_entropy_loss.py#L201 for more details\n            use_sigmoid=True,  # RPN usually performs two-class classification, so it usually uses the sigmoid function.\n            loss_weight=1.0),  # Loss weight of the classification branch.\n        loss_bbox=dict(  # Config of loss function for the regression branch.\n            type='L1Loss',  # Type of loss, we also support many IoU Losses and smooth L1-loss, etc. Refer to https://github.com/open-mmlab/mmdetection/blob/main/mmdet/models/losses/smooth_l1_loss.py#L56 for implementation.\n            loss_weight=1.0)),  # Loss weight of the regression branch.\n    roi_head=dict(  # RoIHead encapsulates the second stage of two-stage/cascade detectors.\n        type='StandardRoIHead',\n        bbox_roi_extractor=dict(  # RoI feature extractor for bbox regression.\n            type='SingleRoIExtractor',  # Type of the RoI feature extractor, most of methods uses SingleRoIExtractor. Refer to https://github.com/open-mmlab/mmdetection/blob/main/mmdet/models/roi_heads/roi_extractors/single_level_roi_extractor.py#L13 for details.\n            roi_layer=dict(  # Config of RoI Layer\n                type='RoIAlign',  # Type of RoI Layer, DeformRoIPoolingPack and ModulatedDeformRoIPoolingPack are also supported. Refer to https://mmcv.readthedocs.io/en/latest/api.html#mmcv.ops.RoIAlign for details.\n                output_size=7,  # The output size of feature maps.\n                sampling_ratio=0),  # Sampling ratio when extracting the RoI features. 0 means adaptive ratio.\n            out_channels=256,  # output channels of the extracted feature.\n            featmap_strides=[4, 8, 16, 32]),  # Strides of multi-scale feature maps. It should be consistent with the architecture of the backbone.\n        bbox_head=dict(  # Config of box head in the RoIHead.\n            type='Shared2FCBBoxHead',  # Type of the bbox head, Refer to https://github.com/open-mmlab/mmdetection/blob/main/mmdet/models/roi_heads/bbox_heads/convfc_bbox_head.py#L220 for implementation details.\n            in_channels=256,  # Input channels for bbox head. This is consistent with the out_channels in roi_extractor\n            fc_out_channels=1024,  # Output feature channels of FC layers.\n            roi_feat_size=7,  # Size of RoI features\n            num_classes=1,  # Number of classes for classification\n            bbox_coder=dict(  # Box coder used in the second stage.\n                type='DeltaXYWHBBoxCoder',  # Type of box coder. 'DeltaXYWHBBoxCoder' is applied for most of the methods.\n                target_means=[0.0, 0.0, 0.0, 0.0],  # Means used to encode and decode box\n                target_stds=[0.1, 0.1, 0.2, 0.2]),  # Standard variance for encoding and decoding. It is smaller since the boxes are more accurate. [0.1, 0.1, 0.2, 0.2] is a conventional setting.\n            reg_class_agnostic=False,  # Whether the regression is class agnostic.\n            loss_cls=dict(  # Config of loss function for the classification branch\n                type='CrossEntropyLoss',  # Type of loss for classification branch, we also support FocalLoss etc.\n                use_sigmoid=False,  # Whether to use sigmoid.\n                loss_weight=1.0),  # Loss weight of the classification branch.\n            loss_bbox=dict(  # Config of loss function for the regression branch.\n                type='L1Loss',  # Type of loss, we also support many IoU Losses and smooth L1-loss, etc.\n                loss_weight=1.0)),  # Loss weight of the regression branch.\n        mask_roi_extractor=dict(  # RoI feature extractor for mask generation.\n            type='SingleRoIExtractor',  # Type of the RoI feature extractor, most of methods uses SingleRoIExtractor.\n            roi_layer=dict(  # Config of RoI Layer that extracts features for instance segmentation\n                type='RoIAlign',  # Type of RoI Layer, DeformRoIPoolingPack and ModulatedDeformRoIPoolingPack are also supported\n                output_size=14,  # The output size of feature maps.\n                sampling_ratio=0),  # Sampling ratio when extracting the RoI features.\n            out_channels=256,  # Output channels of the extracted feature.\n            featmap_strides=[4, 8, 16, 32]),  # Strides of multi-scale feature maps.\n        mask_head=dict(  # Mask prediction head\n            type='FCNMaskHead',  # Type of mask head, refer to https://mmdetection.readthedocs.io/en/latest/api.html#mmdet.models.roi_heads.FCNMaskHead for implementation details.\n            num_convs=4,  # Number of convolutional layers in mask head.\n            in_channels=256,  # Input channels, should be consistent with the output channels of mask roi extractor.\n            conv_out_channels=256,  # Output channels of the convolutional layer.\n            num_classes=1,  # Number of class to be segmented.\n            loss_mask=dict(  # Config of loss function for the mask branch.\n                type='CrossEntropyLoss',  # Type of loss used for segmentation\n                use_mask=True,  # Whether to only train the mask in the correct class.\n                loss_weight=1.0))),  # Loss weight of mask branch.\n    train_cfg = dict(  # Config of training hyperparameters for rpn and rcnn\n        rpn=dict(  # Training config of rpn\n            assigner=dict(  # Config of assigner\n                type='MaxIoUAssigner',  # Type of assigner, MaxIoUAssigner is used for many common detectors. Refer to https://github.com/open-mmlab/mmdetection/blob/main/mmdet/models/task_modules/assigners/max_iou_assigner.py#L14 for more details.\n                pos_iou_thr=0.7,  # IoU >= threshold 0.7 will be taken as positive samples\n                neg_iou_thr=0.3,  # IoU < threshold 0.3 will be taken as negative samples\n                min_pos_iou=0.3,  # The minimal IoU threshold to take boxes as positive samples\n                match_low_quality=True,  # Whether to match the boxes under low quality (see API doc for more details).\n                ignore_iof_thr=-1),  # IoF threshold for ignoring bboxes\n            sampler=dict(  # Config of positive/negative sampler\n                type='RandomSampler',  # Type of sampler, PseudoSampler and other samplers are also supported. Refer to https://github.com/open-mmlab/mmdetection/blob/main/mmdet/models/task_modules/samplers/random_sampler.py#L14 for implementation details.\n                num=256,  # Number of samples\n                pos_fraction=0.5,  # The ratio of positive samples in the total samples.\n                neg_pos_ub=-1,  # The upper bound of negative samples based on the number of positive samples.\n                add_gt_as_proposals=False),  # Whether add GT as proposals after sampling.\n            allowed_border=-1,  # The border allowed after padding for valid anchors.\n            pos_weight=-1,  # The weight of positive samples during training.\n            debug=False),  # Whether to set the debug mode\n        rpn_proposal=dict(  # The config to generate proposals during training\n            nms_across_levels=False,  # Whether to do NMS for boxes across levels. Only work in `GARPNHead`, naive rpn does not support do nms cross levels.\n            nms_pre=2000,  # The number of boxes before NMS\n            nms_post=1000,  # The number of boxes to be kept by NMS. Only work in `GARPNHead`.\n            max_per_img=1000,  # The number of boxes to be kept after NMS.\n            nms=dict( # Config of NMS\n                type='nms',  # Type of NMS\n                iou_threshold=0.7 # NMS threshold\n                ),\n            min_bbox_size=0),  # The allowed minimal box size\n        rcnn=dict(  # The config for the roi heads.\n            assigner=dict(  # Config of assigner for second stage, this is different for that in rpn\n                type='MaxIoUAssigner',  # Type of assigner, MaxIoUAssigner is used for all roi_heads for now. Refer to https://github.com/open-mmlab/mmdetection/blob/main/mmdet/models/task_modules/assigners/max_iou_assigner.py#L14 for more details.\n                pos_iou_thr=0.6,  # IoU >= threshold 0.5 will be taken as positive samples\n                neg_iou_thr=0.6,  # IoU < threshold 0.5 will be taken as negative samples\n                min_pos_iou=0.6,  # The minimal IoU threshold to take boxes as positive samples\n                match_low_quality=False,  # Whether to match the boxes under low quality (see API doc for more details).\n                ignore_iof_thr=-1),  # IoF threshold for ignoring bboxes\n            sampler=dict(\n                type='RandomSampler',  # Type of sampler, PseudoSampler and other samplers are also supported. Refer to https://github.com/open-mmlab/mmdetection/blob/main/mmdet/models/task_modules/samplers/random_sampler.py#L14 for implementation details.\n                num=512,  # Number of samples\n                pos_fraction=0.25,  # The ratio of positive samples in the total samples.\n                neg_pos_ub=-1,  # The upper bound of negative samples based on the number of positive samples.\n                add_gt_as_proposals=True\n            ),  # Whether add GT as proposals after sampling.\n            mask_size=28,  # Size of mask\n            pos_weight=-1,  # The weight of positive samples during training.\n            debug=False)),  # Whether to set the debug mode\n    test_cfg = dict(  # Config for testing hyperparameters for rpn and rcnn\n        rpn=dict(  # The config to generate proposals during testing\n            nms_across_levels=False,  # Whether to do NMS for boxes across levels. Only work in `GARPNHead`, naive rpn does not support do nms cross levels.\n            nms_pre=1000,  # The number of boxes before NMS\n            nms_post=1000,  # The number of boxes to be kept by NMS. Only work in `GARPNHead`.\n            max_per_img=1000,  # The number of boxes to be kept after NMS.\n            nms=dict( # Config of NMS\n                type='nms',  #Type of NMS\n                iou_threshold=0.7 # NMS threshold\n                ),\n            min_bbox_size=0),  # The allowed minimal box size\n        rcnn=dict(  # The config for the roi heads.\n            score_thr=0.05,  # Threshold to filter out boxes\n            nms=dict(  # Config of NMS in the second stage\n                type='nms',  # Type of NMS\n                iou_thr=0.6),  # NMS threshold\n            max_per_img=100,  # Max number of detections of each image\n            mask_thr_binary=0.5)))  # Threshold of mask prediction\n\n# dataset settings\ndataset_type = 'CocoDataset'  # Dataset type, this will be used to define the dataset\ndata_root = ''  # Root path of data\nbackend_args = None # Arguments to instantiate the corresponding file backend\n\nmetainfo = {\n    \"classes\": (\"blood_vessel\",),\n    \"palette\": [(255, 0, 0)]\n}\n\ntrain_pipeline = [  # Training data processing pipeline\n    dict(type='LoadImageFromFile', backend_args=backend_args),  # First pipeline to load images from file path\n    dict(\n        type='LoadAnnotations',  # Second pipeline to load annotations for current image\n        with_bbox=True,  # Whether to use bounding box, True for detection\n        with_mask=True,  # Whether to use instance mask, True for instance segmentation\n        poly2mask=True),  # Whether to convert the polygon mask to instance mask, set False for acceleration and to save memory\n    dict(\n        type='Resize',  # Pipeline that resizes the images and their annotations\n        scale=(512, 512),  # The largest scale of the images\n        keep_ratio=True  # Whether to keep the ratio between height and width\n        ),\n    dict(\n        type='RandomFlip',\n        direction=[\"horizontal\", \"vertical\"],  # Augmentation pipeline that flips the images and their annotations\n        prob=0.5),  # The probability to flip\n    dict(type='PackDetInputs')  # Pipeline that formats the annotation data and decides which keys in the data should be packed into data_samples\n]\n\ntest_pipeline = [  # Testing data processing pipeline\n    dict(type='LoadImageFromFile', backend_args=backend_args),  # First pipeline to load images from file path\n    dict(type='Resize', scale=(512, 512), keep_ratio=True),  # Pipeline that resizes the images\n    dict(\n        type='PackDetInputs',  # Pipeline that formats the annotation data and decides which keys in the data should be packed into data_samples\n        meta_keys=('img_id', 'img_path', 'ori_shape', 'img_shape',\n                   'scale_factor'))\n]\ntrain_dataloader = dict(   # Train dataloader config\n    batch_size=4,  # Batch size of a single GPU\n    num_workers=2,  # Worker to pre-fetch data for each single GPU\n    persistent_workers=True,  # If ``True``, the dataloader will not shut down the worker processes after an epoch end, which can accelerate training speed.\n    sampler=dict(  # training data sampler\n        type='DefaultSampler',  # DefaultSampler which supports both distributed and non-distributed training. Refer to https://mmengine.readthedocs.io/en/latest/api/generated/mmengine.dataset.DefaultSampler.html#mmengine.dataset.DefaultSampler\n        shuffle=True),  # randomly shuffle the training data in each epoch\n    batch_sampler=dict(type='AspectRatioBatchSampler'),  # Batch sampler for grouping images with similar aspect ratio into a same batch. It can reduce GPU memory cost.\n    dataset=dict(  # Train dataset config\n        type=dataset_type,\n        metainfo=metainfo,\n        data_root=\"\",\n        ann_file='/kaggle/input/hubmap-2023-k-fold-cv-coco-dataset-generator/coco_annotations_train_all_fold1.json',  # Path of annotation file\n        data_prefix=dict(img='/kaggle/input/hubmap-hacking-the-human-vasculature/train'),  # Prefix of image path\n        filter_cfg=dict(filter_empty_gt=True, min_size=32),  # Config of filtering images and annotations\n        pipeline=train_pipeline,\n        backend_args=backend_args))\nval_dataloader = dict(  # Validation dataloader config\n    batch_size=1,  # Batch size of a single GPU. If batch-size > 1, the extra padding area may influence the performance.\n    num_workers=2,  # Worker to pre-fetch data for each single GPU\n    persistent_workers=True,  # If ``True``, the dataloader will not shut down the worker processes after an epoch end, which can accelerate training speed.\n    drop_last=False,  # Whether to drop the last incomplete batch, if the dataset size is not divisible by the batch size\n    sampler=dict(\n        type='DefaultSampler',\n        shuffle=False),  # not shuffle during validation and testing\n    dataset=dict(\n        type=dataset_type,\n        metainfo=metainfo,\n        data_root=\"\",\n        ann_file='/kaggle/input/hubmap-2023-k-fold-cv-coco-dataset-generator/coco_annotations_valid_all_fold1.json',\n        data_prefix=dict(img='/kaggle/input/hubmap-hacking-the-human-vasculature/train'),\n        test_mode=True,  # Turn on the test mode of the dataset to avoid filtering annotations or images\n        pipeline=test_pipeline,\n        backend_args=backend_args))\ntest_dataloader = val_dataloader  # Testing dataloader config\n\n# setting evaluator\nval_evaluator = dict(  # Validation evaluator config\n    type='CocoMetric',  # The coco metric used to evaluate AR, AP, and mAP for detection and instance segmentation\n    ann_file='/kaggle/input/hubmap-2023-k-fold-cv-coco-dataset-generator/coco_annotations_valid_all_fold1.json',  # Annotation file path\n    metric=['segm'],  # Metrics to be evaluated, `bbox` for detection and `segm` for instance segmentation\n    format_only=False,\n    # backend_args=backend_args\n    backend_args=None,\n    # iou_thrs=[0.6]\n    )\ntest_evaluator = val_evaluator  # Testing evaluator config\n\n# setting optimizer\noptim_wrapper = dict(  # Optimizer wrapper config\n    type='OptimWrapper',  # Optimizer wrapper type, switch to AmpOptimWrapper to enable mixed precision training.\n    optimizer=dict(  # Optimizer config. Support all kinds of optimizers in PyTorch. Refer to https://pytorch.org/docs/stable/optim.html#algorithms\n        type='SGD',  # Stochastic gradient descent optimizer\n        lr=0.02,  # The base learning rate\n        momentum=0.9,  # Stochastic gradient descent with momentum\n        weight_decay=0.0001),  # Weight decay of SGD\n    clip_grad=None,  # Gradient clip option. Set None to disable gradient clip. Find usage in https://mmengine.readthedocs.io/en/latest/tutorials/optimizer.html\n    )\n\n# setting scheduler\nparam_scheduler = [\n    # Linear learning rate warm-up scheduler\n    dict(\n        type='LinearLR',  # Use linear policy to warmup learning rate\n        start_factor=0.001, # The ratio of the starting learning rate used for warmup\n        by_epoch=False,  # The warmup learning rate is updated by iteration\n        begin=0,  # Start from the first iteration\n        end=500),  # End the warmup at the 500th iteration\n    # The main LRScheduler\n    dict(\n        type='MultiStepLR',  # Use multi-step learning rate policy during training\n        by_epoch=True,  # The learning rate is updated by epoch\n        begin=0,   # Start from the first epoch\n        end=12,  # End at the 12th epoch\n        milestones=[8, 11],  # Epochs to decay the learning rate\n        gamma=0.1)  # The learning rate decay ratio\n]\n\n# setting hook\ndefault_hooks = dict(\n    timer=dict(type='IterTimerHook'),  # Update the time spent during iteration into message hub\n    logger=dict(type='LoggerHook', interval=50),  # Collect logs from different components of Runner and write them to terminal, JSON file, tensorboard and wandb .etc\n    param_scheduler=dict(type='ParamSchedulerHook'), # update some hyper-parameters of optimizer\n    checkpoint=dict(type='CheckpointHook', interval=1, save_best=\"coco/segm_mAP\"), # Save checkpoints periodically\n    sampler_seed=dict(type='DistSamplerSeedHook'),  # Ensure distributed Sampler shuffle is active\n    visualization=dict(type='DetVisualizationHook'))  # Detection Visualization Hook. Used to visualize validation and testing process prediction results\n\ncustom_hooks = [dict(\n        type='EarlyStoppingHook',\n        monitor='coco/segm_mAP',\n        rule='greater',\n        min_delta=0.005,\n        strict=False,\n        check_finite=True,\n        patience=2,\n        stopping_threshold=None)]\n\n# setting scope\ndefault_scope = 'mmdet'  # The default registry scope to find modules. Refer to https://mmengine.readthedocs.io/en/latest/advanced_tutorials/registry.html\n\n# setting env config\nenv_cfg = dict(\n    cudnn_benchmark=False,  # Whether to enable cudnn benchmark\n    mp_cfg=dict(  # Multi-processing config\n        mp_start_method='fork',  # Use fork to start multi-processing threads. 'fork' usually faster than 'spawn' but maybe unsafe. See discussion in https://github.com/pytorch/pytorch/issues/1355\n        opencv_num_threads=0),  # Disable opencv multi-threads to avoid system being overloaded\n    dist_cfg=dict(backend='nccl'),  # Distribution configs\n)\n\n# setting visualizer\nvis_backends = [dict(type='LocalVisBackend')]  # Visualization backends. Refer to https://mmengine.readthedocs.io/en/latest/advanced_tutorials/visualization.html\nvisualizer = dict(\n    # type='DetLocalVisualizer', vis_backends=vis_backends, name='visualizer'\n    type=\"Visualizer\", vis_backends=[dict(type=\"WandbVisBackend\")]\n    )\n\nlog_config = dict(\n    hooks = [\n    dict(type='TextLoggerHook'),\n        dict(type='MMDetWandbHook',\n            init_kwargs={'project': 'mmdetection'},\n            interval=10,\n            log_checkpoint=True,\n            log_checkpoint_metadata=True,\n            num_eval_images=100,\n            bbox_score_thr=0.3)\n    ]\n)\n\n# settiing logger\nlog_processor = dict(\n    type='LogProcessor',  # Log processor to process runtime logs\n    window_size=50,  # Smooth interval of log values\n    by_epoch=True)  # Whether to format logs with epoch type. Should be consistent with the train loop's type.\nlog_level = 'INFO'  # The level of logging.\nload_from = None  # Load model checkpoint as a pre-trained model from a given path. This will not resume training.\nresume = False  # Whether to resume from the checkpoint defined in `load_from`. If `load_from` is None, it will resume the latest checkpoint in the `work_dir`.\n\n# setting trian test cfg\ntrain_cfg = dict(\n    type='EpochBasedTrainLoop',  # The training loop type. Refer to https://github.com/open-mmlab/mmengine/blob/main/mmengine/runner/loops.py\n    max_epochs=12,  # Maximum training epochs\n    val_interval=1)  # Validation intervals. Run validation every epoch.\nval_cfg = dict(type='ValLoop')  # The validation loop type\ntest_cfg = dict(type='TestLoop')  # The testing loop type\n\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qfxn8mFVPNnT","outputId":"080cdf1a-caf4-4973-e679-e71c14ec525c","execution":{"iopub.status.busy":"2023-06-28T12:42:49.323880Z","iopub.execute_input":"2023-06-28T12:42:49.324269Z","iopub.status.idle":"2023-06-28T12:42:49.354237Z","shell.execute_reply.started":"2023-06-28T12:42:49.324225Z","shell.execute_reply":"2023-06-28T12:42:49.353261Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Writing /kaggle/working/configs/custom_config.py\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Train","metadata":{"id":"wkc1wmEA87LT"}},{"cell_type":"code","source":"%mkdir work_dir\nfrom mmengine.config import Config\nfrom mmengine.runner import Runner\n\nfrom mmdet.utils import register_all_modules\n\ncfg = Config.fromfile(\"/kaggle/working/configs/custom_config.py\")\n\ncfg.work_dir = \"/kaggle/working/work_dir\"\nrunner = Runner.from_cfg(cfg)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RQ5Dk2ZZeh6r","outputId":"ec542c97-8e19-438e-aaa4-8d5c9830f23d","execution":{"iopub.status.busy":"2023-06-28T12:43:14.202303Z","iopub.execute_input":"2023-06-28T12:43:14.202670Z","iopub.status.idle":"2023-06-28T12:44:02.407620Z","shell.execute_reply.started":"2023-06-28T12:43:14.202639Z","shell.execute_reply":"2023-06-28T12:44:02.406582Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"mkdir: cannot create directory ‘work_dir’: File exists\n06/28 12:43:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n------------------------------------------------------------\nSystem environment:\n    sys.platform: linux\n    Python: 3.10.10 | packaged by conda-forge | (main, Mar 24 2023, 20:08:06) [GCC 11.3.0]\n    CUDA available: True\n    numpy_random_seed: 1537622402\n    GPU 0: Tesla P100-PCIE-16GB\n    CUDA_HOME: /usr/local/cuda\n    NVCC: Cuda compilation tools, release 11.8, V11.8.89\n    GCC: gcc (Ubuntu 11.3.0-1ubuntu1~22.04) 11.3.0\n    PyTorch: 2.0.0\n    PyTorch compiling details: PyTorch built with:\n  - GCC 11.3\n  - C++ Version: 201703\n  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications\n  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)\n  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n  - LAPACK is enabled (usually provided by MKL)\n  - NNPACK is enabled\n  - CPU capability usage: AVX2\n  - CUDA Runtime 11.8\n  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_70,code=compute_70;-gencode;arch=compute_75,code=compute_75\n  - CuDNN 8.7\n  - Magma 2.6.1\n  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=1 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=range-loop-construct -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n\n    TorchVision: 0.15.1\n    OpenCV: 4.7.0\n    MMEngine: 0.7.3\n\nRuntime environment:\n    cudnn_benchmark: False\n    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n    dist_cfg: {'backend': 'nccl'}\n    seed: None\n    Distributed launcher: none\n    Distributed training: False\n    GPU number: 1\n------------------------------------------------------------\n\n06/28 12:43:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\nmodel = dict(\n    type='MaskRCNN',\n    data_preprocessor=dict(\n        type='DetDataPreprocessor',\n        mean=[123.675, 116.28, 103.53],\n        std=[58.395, 57.12, 57.375],\n        bgr_to_rgb=True,\n        pad_mask=True,\n        pad_size_divisor=32),\n    backbone=dict(\n        type='ResNet',\n        depth=50,\n        num_stages=4,\n        out_indices=(0, 1, 2, 3),\n        frozen_stages=1,\n        norm_cfg=dict(type='BN', requires_grad=True),\n        norm_eval=True,\n        style='pytorch',\n        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet50')),\n    neck=dict(\n        type='FPN',\n        in_channels=[256, 512, 1024, 2048],\n        out_channels=256,\n        num_outs=5),\n    rpn_head=dict(\n        type='RPNHead',\n        in_channels=256,\n        feat_channels=256,\n        anchor_generator=dict(\n            type='AnchorGenerator',\n            scales=[8],\n            ratios=[0.5, 1.0, 2.0],\n            strides=[4, 8, 16, 32, 64]),\n        bbox_coder=dict(\n            type='DeltaXYWHBBoxCoder',\n            target_means=[0.0, 0.0, 0.0, 0.0],\n            target_stds=[1.0, 1.0, 1.0, 1.0]),\n        loss_cls=dict(\n            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n        loss_bbox=dict(type='L1Loss', loss_weight=1.0)),\n    roi_head=dict(\n        type='StandardRoIHead',\n        bbox_roi_extractor=dict(\n            type='SingleRoIExtractor',\n            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=0),\n            out_channels=256,\n            featmap_strides=[4, 8, 16, 32]),\n        bbox_head=dict(\n            type='Shared2FCBBoxHead',\n            in_channels=256,\n            fc_out_channels=1024,\n            roi_feat_size=7,\n            num_classes=1,\n            bbox_coder=dict(\n                type='DeltaXYWHBBoxCoder',\n                target_means=[0.0, 0.0, 0.0, 0.0],\n                target_stds=[0.1, 0.1, 0.2, 0.2]),\n            reg_class_agnostic=False,\n            loss_cls=dict(\n                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),\n            loss_bbox=dict(type='L1Loss', loss_weight=1.0)),\n        mask_roi_extractor=dict(\n            type='SingleRoIExtractor',\n            roi_layer=dict(type='RoIAlign', output_size=14, sampling_ratio=0),\n            out_channels=256,\n            featmap_strides=[4, 8, 16, 32]),\n        mask_head=dict(\n            type='FCNMaskHead',\n            num_convs=4,\n            in_channels=256,\n            conv_out_channels=256,\n            num_classes=1,\n            loss_mask=dict(\n                type='CrossEntropyLoss', use_mask=True, loss_weight=1.0))),\n    train_cfg=dict(\n        rpn=dict(\n            assigner=dict(\n                type='MaxIoUAssigner',\n                pos_iou_thr=0.7,\n                neg_iou_thr=0.3,\n                min_pos_iou=0.3,\n                match_low_quality=True,\n                ignore_iof_thr=-1),\n            sampler=dict(\n                type='RandomSampler',\n                num=256,\n                pos_fraction=0.5,\n                neg_pos_ub=-1,\n                add_gt_as_proposals=False),\n            allowed_border=-1,\n            pos_weight=-1,\n            debug=False),\n        rpn_proposal=dict(\n            nms_across_levels=False,\n            nms_pre=2000,\n            nms_post=1000,\n            max_per_img=1000,\n            nms=dict(type='nms', iou_threshold=0.7),\n            min_bbox_size=0),\n        rcnn=dict(\n            assigner=dict(\n                type='MaxIoUAssigner',\n                pos_iou_thr=0.6,\n                neg_iou_thr=0.6,\n                min_pos_iou=0.6,\n                match_low_quality=False,\n                ignore_iof_thr=-1),\n            sampler=dict(\n                type='RandomSampler',\n                num=512,\n                pos_fraction=0.25,\n                neg_pos_ub=-1,\n                add_gt_as_proposals=True),\n            mask_size=28,\n            pos_weight=-1,\n            debug=False)),\n    test_cfg=dict(\n        rpn=dict(\n            nms_across_levels=False,\n            nms_pre=1000,\n            nms_post=1000,\n            max_per_img=1000,\n            nms=dict(type='nms', iou_threshold=0.7),\n            min_bbox_size=0),\n        rcnn=dict(\n            score_thr=0.05,\n            nms=dict(type='nms', iou_thr=0.6),\n            max_per_img=100,\n            mask_thr_binary=0.5)))\ndataset_type = 'CocoDataset'\ndata_root = ''\nbackend_args = None\nmetainfo = dict(classes=('blood_vessel', ), palette=[(255, 0, 0)])\ntrain_pipeline = [\n    dict(type='LoadImageFromFile', backend_args=None),\n    dict(\n        type='LoadAnnotations', with_bbox=True, with_mask=True,\n        poly2mask=True),\n    dict(type='Resize', scale=(512, 512), keep_ratio=True),\n    dict(type='RandomFlip', direction=['horizontal', 'vertical'], prob=0.5),\n    dict(type='PackDetInputs')\n]\ntest_pipeline = [\n    dict(type='LoadImageFromFile', backend_args=None),\n    dict(type='Resize', scale=(512, 512), keep_ratio=True),\n    dict(\n        type='PackDetInputs',\n        meta_keys=('img_id', 'img_path', 'ori_shape', 'img_shape',\n                   'scale_factor'))\n]\ntrain_dataloader = dict(\n    batch_size=4,\n    num_workers=4,\n    persistent_workers=True,\n    sampler=dict(type='DefaultSampler', shuffle=True),\n    batch_sampler=dict(type='AspectRatioBatchSampler'),\n    dataset=dict(\n        type='CocoDataset',\n        metainfo=dict(classes=('blood_vessel', ), palette=[(255, 0, 0)]),\n        data_root='',\n        ann_file=\n        '/kaggle/input/hubmap-2023-k-fold-cv-coco-dataset-generator/coco_annotations_train_all_fold1.json',\n        data_prefix=dict(\n            img='/kaggle/input/hubmap-hacking-the-human-vasculature/train'),\n        filter_cfg=dict(filter_empty_gt=True, min_size=32),\n        pipeline=[\n            dict(type='LoadImageFromFile', backend_args=None),\n            dict(\n                type='LoadAnnotations',\n                with_bbox=True,\n                with_mask=True,\n                poly2mask=True),\n            dict(type='Resize', scale=(512, 512), keep_ratio=True),\n            dict(\n                type='RandomFlip',\n                direction=['horizontal', 'vertical'],\n                prob=0.5),\n            dict(type='PackDetInputs')\n        ],\n        backend_args=None))\nval_dataloader = dict(\n    batch_size=1,\n    num_workers=2,\n    persistent_workers=True,\n    drop_last=False,\n    sampler=dict(type='DefaultSampler', shuffle=False),\n    dataset=dict(\n        type='CocoDataset',\n        metainfo=dict(classes=('blood_vessel', ), palette=[(255, 0, 0)]),\n        data_root='',\n        ann_file=\n        '/kaggle/input/hubmap-2023-k-fold-cv-coco-dataset-generator/coco_annotations_valid_all_fold1.json',\n        data_prefix=dict(\n            img='/kaggle/input/hubmap-hacking-the-human-vasculature/train'),\n        test_mode=True,\n        pipeline=[\n            dict(type='LoadImageFromFile', backend_args=None),\n            dict(type='Resize', scale=(512, 512), keep_ratio=True),\n            dict(\n                type='PackDetInputs',\n                meta_keys=('img_id', 'img_path', 'ori_shape', 'img_shape',\n                           'scale_factor'))\n        ],\n        backend_args=None))\ntest_dataloader = dict(\n    batch_size=1,\n    num_workers=2,\n    persistent_workers=True,\n    drop_last=False,\n    sampler=dict(type='DefaultSampler', shuffle=False),\n    dataset=dict(\n        type='CocoDataset',\n        metainfo=dict(classes=('blood_vessel', ), palette=[(255, 0, 0)]),\n        data_root='',\n        ann_file=\n        '/kaggle/input/hubmap-2023-k-fold-cv-coco-dataset-generator/coco_annotations_valid_all_fold1.json',\n        data_prefix=dict(\n            img='/kaggle/input/hubmap-hacking-the-human-vasculature/train'),\n        test_mode=True,\n        pipeline=[\n            dict(type='LoadImageFromFile', backend_args=None),\n            dict(type='Resize', scale=(512, 512), keep_ratio=True),\n            dict(\n                type='PackDetInputs',\n                meta_keys=('img_id', 'img_path', 'ori_shape', 'img_shape',\n                           'scale_factor'))\n        ],\n        backend_args=None))\nval_evaluator = dict(\n    type='CocoMetric',\n    ann_file=\n    '/kaggle/input/hubmap-2023-k-fold-cv-coco-dataset-generator/coco_annotations_valid_all_fold1.json',\n    metric=['segm'],\n    format_only=False,\n    backend_args=None)\ntest_evaluator = dict(\n    type='CocoMetric',\n    ann_file=\n    '/kaggle/input/hubmap-2023-k-fold-cv-coco-dataset-generator/coco_annotations_valid_all_fold1.json',\n    metric=['segm'],\n    format_only=False,\n    backend_args=None)\noptim_wrapper = dict(\n    type='OptimWrapper',\n    optimizer=dict(type='SGD', lr=0.02, momentum=0.9, weight_decay=0.0001),\n    clip_grad=None)\nparam_scheduler = [\n    dict(\n        type='LinearLR', start_factor=0.001, by_epoch=False, begin=0, end=500),\n    dict(\n        type='MultiStepLR',\n        by_epoch=True,\n        begin=0,\n        end=12,\n        milestones=[8, 11],\n        gamma=0.1)\n]\ndefault_hooks = dict(\n    timer=dict(type='IterTimerHook'),\n    logger=dict(type='LoggerHook', interval=50),\n    param_scheduler=dict(type='ParamSchedulerHook'),\n    checkpoint=dict(\n        type='CheckpointHook', interval=1, save_best='coco/segm_mAP'),\n    sampler_seed=dict(type='DistSamplerSeedHook'),\n    visualization=dict(type='DetVisualizationHook'))\ncustom_hooks = [\n    dict(\n        type='EarlyStoppingHook',\n        monitor='coco/segm_mAP',\n        rule='greater',\n        min_delta=0.005,\n        strict=False,\n        check_finite=True,\n        patience=2,\n        stopping_threshold=None)\n]\ndefault_scope = 'mmdet'\nenv_cfg = dict(\n    cudnn_benchmark=False,\n    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0),\n    dist_cfg=dict(backend='nccl'))\nvis_backends = [dict(type='LocalVisBackend')]\nvisualizer = dict(\n    type='Visualizer', vis_backends=[dict(type='WandbVisBackend')])\nlog_config = dict(hooks=[\n    dict(type='TextLoggerHook'),\n    dict(\n        type='MMDetWandbHook',\n        init_kwargs=dict(project='mmdetection'),\n        interval=10,\n        log_checkpoint=True,\n        log_checkpoint_metadata=True,\n        num_eval_images=100,\n        bbox_score_thr=0.3)\n])\nlog_processor = dict(type='LogProcessor', window_size=50, by_epoch=True)\nlog_level = 'INFO'\nload_from = None\nresume = False\ntrain_cfg = dict(type='EpochBasedTrainLoop', max_epochs=12, val_interval=1)\nval_cfg = dict(type='ValLoop')\ntest_cfg = dict(type='TestLoop')\nwork_dir = '/kaggle/working/work_dir'\n\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mando0718\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.15.4"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/work_dir/20230628_124315/vis_data/wandb/run-20230628_124321-g00ckxe1</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/ando0718/uncategorized/runs/g00ckxe1' target=\"_blank\">twilight-salad-30</a></strong> to <a href='https://wandb.ai/ando0718/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/ando0718/uncategorized' target=\"_blank\">https://wandb.ai/ando0718/uncategorized</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/ando0718/uncategorized/runs/g00ckxe1' target=\"_blank\">https://wandb.ai/ando0718/uncategorized/runs/g00ckxe1</a>"},"metadata":{}},{"name":"stdout","text":"06/28 12:43:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n06/28 12:43:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\nbefore_run:\n(VERY_HIGH   ) RuntimeInfoHook                    \n(BELOW_NORMAL) LoggerHook                         \n(LOWEST      ) EarlyStoppingHook                  \n -------------------- \nbefore_train:\n(VERY_HIGH   ) RuntimeInfoHook                    \n(NORMAL      ) IterTimerHook                      \n(VERY_LOW    ) CheckpointHook                     \n -------------------- \nbefore_train_epoch:\n(VERY_HIGH   ) RuntimeInfoHook                    \n(NORMAL      ) IterTimerHook                      \n(NORMAL      ) DistSamplerSeedHook                \n -------------------- \nbefore_train_iter:\n(VERY_HIGH   ) RuntimeInfoHook                    \n(NORMAL      ) IterTimerHook                      \n -------------------- \nafter_train_iter:\n(VERY_HIGH   ) RuntimeInfoHook                    \n(NORMAL      ) IterTimerHook                      \n(BELOW_NORMAL) LoggerHook                         \n(LOW         ) ParamSchedulerHook                 \n(VERY_LOW    ) CheckpointHook                     \n -------------------- \nafter_train_epoch:\n(NORMAL      ) IterTimerHook                      \n(LOW         ) ParamSchedulerHook                 \n(VERY_LOW    ) CheckpointHook                     \n -------------------- \nbefore_val_epoch:\n(NORMAL      ) IterTimerHook                      \n -------------------- \nbefore_val_iter:\n(NORMAL      ) IterTimerHook                      \n -------------------- \nafter_val_iter:\n(NORMAL      ) IterTimerHook                      \n(NORMAL      ) DetVisualizationHook               \n(BELOW_NORMAL) LoggerHook                         \n -------------------- \nafter_val_epoch:\n(VERY_HIGH   ) RuntimeInfoHook                    \n(NORMAL      ) IterTimerHook                      \n(BELOW_NORMAL) LoggerHook                         \n(LOW         ) ParamSchedulerHook                 \n(VERY_LOW    ) CheckpointHook                     \n(LOWEST      ) EarlyStoppingHook                  \n -------------------- \nafter_train:\n(VERY_LOW    ) CheckpointHook                     \n -------------------- \nbefore_test_epoch:\n(NORMAL      ) IterTimerHook                      \n -------------------- \nbefore_test_iter:\n(NORMAL      ) IterTimerHook                      \n -------------------- \nafter_test_iter:\n(NORMAL      ) IterTimerHook                      \n(NORMAL      ) DetVisualizationHook               \n(BELOW_NORMAL) LoggerHook                         \n -------------------- \nafter_test_epoch:\n(VERY_HIGH   ) RuntimeInfoHook                    \n(NORMAL      ) IterTimerHook                      \n(BELOW_NORMAL) LoggerHook                         \n -------------------- \nafter_run:\n(BELOW_NORMAL) LoggerHook                         \n -------------------- \n","output_type":"stream"}]},{"cell_type":"code","source":"runner.train()","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"8JdOs8sde9d5","outputId":"9d909517-c530-425a-e797-e6c3407c8b81","execution":{"iopub.status.busy":"2023-06-28T12:44:02.409568Z","iopub.execute_input":"2023-06-28T12:44:02.410300Z","iopub.status.idle":"2023-06-28T13:00:53.610495Z","shell.execute_reply.started":"2023-06-28T12:44:02.410256Z","shell.execute_reply":"2023-06-28T13:00:53.609522Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"loading annotations into memory...\nDone (t=0.89s)\ncreating index...\nindex created!\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  warnings.warn(_create_warning_msg(\n","output_type":"stream"},{"name":"stdout","text":"loading annotations into memory...\nDone (t=0.22s)\ncreating index...\nindex created!\nloading annotations into memory...\nDone (t=0.11s)\ncreating index...\nindex created!\n06/28 12:44:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - load model from: torchvision://resnet50\n06/28 12:44:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Loads checkpoint by torchvision backend from path: torchvision://resnet50\n","output_type":"stream"},{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n","output_type":"stream"},{"name":"stdout","text":"06/28 12:44:09 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - The model and loaded state dict do not match exactly\n\nunexpected key in source state_dict: fc.weight, fc.bias\n\n06/28 12:44:09 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n06/28 12:44:09 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n06/28 12:44:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /kaggle/working/work_dir.\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  warnings.warn(_create_warning_msg(\n","output_type":"stream"},{"name":"stdout","text":"06/28 12:44:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 50/324]  lr: 1.9820e-03  eta: 0:33:55  time: 0.5303  data_time: 0.0693  memory: 2053  loss: 1.7567  loss_rpn_cls: 0.6533  loss_rpn_bbox: 0.1278  loss_cls: 0.2036  acc: 96.9238  loss_bbox: 0.0131  loss_mask: 0.7590\n06/28 12:44:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][100/324]  lr: 3.9840e-03  eta: 0:28:24  time: 0.3694  data_time: 0.0419  memory: 2065  loss: 1.1903  loss_rpn_cls: 0.4419  loss_rpn_bbox: 0.1157  loss_cls: 0.1006  acc: 97.8516  loss_bbox: 0.0156  loss_mask: 0.5165\n06/28 12:45:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][150/324]  lr: 5.9860e-03  eta: 0:26:09  time: 0.3598  data_time: 0.0397  memory: 2212  loss: 1.1048  loss_rpn_cls: 0.3253  loss_rpn_bbox: 0.1001  loss_cls: 0.1404  acc: 96.0449  loss_bbox: 0.0550  loss_mask: 0.4841\n06/28 12:45:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][200/324]  lr: 7.9880e-03  eta: 0:24:36  time: 0.3416  data_time: 0.0369  memory: 2371  loss: 1.0270  loss_rpn_cls: 0.2492  loss_rpn_bbox: 0.1087  loss_cls: 0.1664  acc: 94.8730  loss_bbox: 0.0856  loss_mask: 0.4172\n06/28 12:45:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][250/324]  lr: 9.9900e-03  eta: 0:23:47  time: 0.3607  data_time: 0.0417  memory: 2485  loss: 0.9832  loss_rpn_cls: 0.1947  loss_rpn_bbox: 0.0993  loss_cls: 0.1778  acc: 92.1875  loss_bbox: 0.1128  loss_mask: 0.3988\n06/28 12:46:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][300/324]  lr: 1.1992e-02  eta: 0:23:08  time: 0.3603  data_time: 0.0365  memory: 2472  loss: 0.9811  loss_rpn_cls: 0.1867  loss_rpn_bbox: 0.0934  loss_cls: 0.1854  acc: 89.7461  loss_bbox: 0.1257  loss_mask: 0.3900\n06/28 12:46:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: custom_config_20230628_124315\n06/28 12:46:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 1 epochs\n06/28 12:46:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [1][ 50/327]    eta: 0:00:28  time: 0.1017  data_time: 0.0041  memory: 2335  \n06/28 12:46:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [1][100/327]    eta: 0:00:22  time: 0.0963  data_time: 0.0020  memory: 731  \n06/28 12:46:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [1][150/327]    eta: 0:00:16  time: 0.0901  data_time: 0.0018  memory: 731  \n06/28 12:46:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [1][200/327]    eta: 0:00:12  time: 0.1113  data_time: 0.0020  memory: 731  \n06/28 12:46:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [1][250/327]    eta: 0:00:07  time: 0.0938  data_time: 0.0018  memory: 731  \n06/28 12:46:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [1][300/327]    eta: 0:00:02  time: 0.0933  data_time: 0.0018  memory: 731  \n06/28 12:46:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Evaluating segm...\nLoading and preparing results...\nDONE (t=0.39s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *segm*\nDONE (t=10.84s).\nAccumulating evaluation results...\nDONE (t=1.15s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.071\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.212\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.025\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.082\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.072\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.000\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.277\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.277\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.277\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.300\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.226\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.024\n06/28 12:47:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - segm_mAP_copypaste: 0.071 0.212 0.025 0.082 0.072 0.000\n06/28 12:47:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][327/327]    coco/segm_mAP: 0.0710  coco/segm_mAP_50: 0.2120  coco/segm_mAP_75: 0.0250  coco/segm_mAP_s: 0.0820  coco/segm_mAP_m: 0.0720  coco/segm_mAP_l: 0.0000  data_time: 0.0022  time: 0.0970\n06/28 12:47:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.0710 coco/segm_mAP at 1 epoch is saved to best_coco_segm_mAP_epoch_1.pth.\n06/28 12:47:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 50/324]  lr: 1.4955e-02  eta: 0:22:23  time: 0.3724  data_time: 0.0497  memory: 2605  loss: 0.9694  loss_rpn_cls: 0.1669  loss_rpn_bbox: 0.0945  loss_cls: 0.1896  acc: 92.3828  loss_bbox: 0.1533  loss_mask: 0.3651\n06/28 12:47:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][100/324]  lr: 1.6957e-02  eta: 0:21:58  time: 0.3688  data_time: 0.0386  memory: 2771  loss: 0.9677  loss_rpn_cls: 0.1570  loss_rpn_bbox: 0.0904  loss_cls: 0.1958  acc: 90.2344  loss_bbox: 0.1613  loss_mask: 0.3632\n06/28 12:48:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][150/324]  lr: 1.8959e-02  eta: 0:21:31  time: 0.3593  data_time: 0.0371  memory: 2570  loss: 0.9540  loss_rpn_cls: 0.1567  loss_rpn_bbox: 0.0887  loss_cls: 0.1967  acc: 87.9395  loss_bbox: 0.1607  loss_mask: 0.3512\n06/28 12:48:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][200/324]  lr: 2.0000e-02  eta: 0:21:12  time: 0.3766  data_time: 0.0369  memory: 2859  loss: 0.9795  loss_rpn_cls: 0.1440  loss_rpn_bbox: 0.0929  loss_cls: 0.2211  acc: 94.8242  loss_bbox: 0.1881  loss_mask: 0.3333\n06/28 12:48:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][250/324]  lr: 2.0000e-02  eta: 0:20:49  time: 0.3626  data_time: 0.0378  memory: 2618  loss: 0.9137  loss_rpn_cls: 0.1210  loss_rpn_bbox: 0.0802  loss_cls: 0.1983  acc: 95.8984  loss_bbox: 0.1730  loss_mask: 0.3411\n06/28 12:48:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][300/324]  lr: 2.0000e-02  eta: 0:20:28  time: 0.3717  data_time: 0.0362  memory: 2817  loss: 0.9205  loss_rpn_cls: 0.1268  loss_rpn_bbox: 0.0824  loss_cls: 0.1992  acc: 96.0449  loss_bbox: 0.1752  loss_mask: 0.3368\n06/28 12:49:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: custom_config_20230628_124315\n06/28 12:49:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 2 epochs\n06/28 12:49:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [2][ 50/327]    eta: 0:00:26  time: 0.0943  data_time: 0.0027  memory: 2729  \n06/28 12:49:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [2][100/327]    eta: 0:00:19  time: 0.0800  data_time: 0.0018  memory: 731  \n06/28 12:49:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [2][150/327]    eta: 0:00:15  time: 0.0808  data_time: 0.0018  memory: 731  \n06/28 12:49:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [2][200/327]    eta: 0:00:10  time: 0.0828  data_time: 0.0018  memory: 731  \n06/28 12:49:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [2][250/327]    eta: 0:00:06  time: 0.0843  data_time: 0.0018  memory: 731  \n06/28 12:49:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [2][300/327]    eta: 0:00:02  time: 0.0852  data_time: 0.0019  memory: 731  \n06/28 12:49:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Evaluating segm...\nLoading and preparing results...\nDONE (t=0.30s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *segm*\nDONE (t=9.24s).\nAccumulating evaluation results...\nDONE (t=0.87s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.171\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.418\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.089\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.179\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.182\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.138\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.350\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.350\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.350\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.327\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.423\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.298\n06/28 12:49:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - segm_mAP_copypaste: 0.171 0.418 0.089 0.179 0.182 0.138\n06/28 12:49:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [2][327/327]    coco/segm_mAP: 0.1710  coco/segm_mAP_50: 0.4180  coco/segm_mAP_75: 0.0890  coco/segm_mAP_s: 0.1790  coco/segm_mAP_m: 0.1820  coco/segm_mAP_l: 0.1380  data_time: 0.0019  time: 0.0837\n06/28 12:49:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint /kaggle/working/work_dir/best_coco_segm_mAP_epoch_1.pth is removed\n06/28 12:49:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.1710 coco/segm_mAP at 2 epoch is saved to best_coco_segm_mAP_epoch_2.pth.\n06/28 12:50:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 50/324]  lr: 2.0000e-02  eta: 0:20:00  time: 0.3791  data_time: 0.0448  memory: 2648  loss: 0.9110  loss_rpn_cls: 0.1126  loss_rpn_bbox: 0.0798  loss_cls: 0.2043  acc: 91.6016  loss_bbox: 0.1870  loss_mask: 0.3273\n06/28 12:50:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][100/324]  lr: 2.0000e-02  eta: 0:19:40  time: 0.3721  data_time: 0.0343  memory: 2729  loss: 0.8998  loss_rpn_cls: 0.1147  loss_rpn_bbox: 0.0774  loss_cls: 0.2006  acc: 90.4297  loss_bbox: 0.1840  loss_mask: 0.3231\n06/28 12:50:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][150/324]  lr: 2.0000e-02  eta: 0:19:22  time: 0.3802  data_time: 0.0366  memory: 2723  loss: 0.9045  loss_rpn_cls: 0.1019  loss_rpn_bbox: 0.0787  loss_cls: 0.2117  acc: 93.7012  loss_bbox: 0.1972  loss_mask: 0.3151\n06/28 12:51:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][200/324]  lr: 2.0000e-02  eta: 0:19:03  time: 0.3756  data_time: 0.0382  memory: 2742  loss: 0.8985  loss_rpn_cls: 0.0981  loss_rpn_bbox: 0.0801  loss_cls: 0.2097  acc: 90.3320  loss_bbox: 0.1999  loss_mask: 0.3107\n06/28 12:51:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][250/324]  lr: 2.0000e-02  eta: 0:18:45  time: 0.3806  data_time: 0.0406  memory: 2664  loss: 0.8674  loss_rpn_cls: 0.0988  loss_rpn_bbox: 0.0754  loss_cls: 0.1981  acc: 92.5781  loss_bbox: 0.1918  loss_mask: 0.3033\n06/28 12:51:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][300/324]  lr: 2.0000e-02  eta: 0:18:25  time: 0.3655  data_time: 0.0325  memory: 2801  loss: 0.8567  loss_rpn_cls: 0.0976  loss_rpn_bbox: 0.0728  loss_cls: 0.1891  acc: 89.1113  loss_bbox: 0.1825  loss_mask: 0.3147\n06/28 12:51:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: custom_config_20230628_124315\n06/28 12:51:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 3 epochs\n06/28 12:52:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [3][ 50/327]    eta: 0:00:23  time: 0.0836  data_time: 0.0023  memory: 2736  \n06/28 12:52:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [3][100/327]    eta: 0:00:18  time: 0.0814  data_time: 0.0018  memory: 731  \n06/28 12:52:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [3][150/327]    eta: 0:00:14  time: 0.0776  data_time: 0.0017  memory: 731  \n06/28 12:52:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [3][200/327]    eta: 0:00:10  time: 0.0822  data_time: 0.0018  memory: 731  \n06/28 12:52:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [3][250/327]    eta: 0:00:06  time: 0.0834  data_time: 0.0018  memory: 731  \n06/28 12:52:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [3][300/327]    eta: 0:00:02  time: 0.0881  data_time: 0.0027  memory: 731  \n06/28 12:52:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Evaluating segm...\nLoading and preparing results...\nDONE (t=0.28s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *segm*\nDONE (t=8.84s).\nAccumulating evaluation results...\nDONE (t=0.87s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.215\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.500\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.133\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.217\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.223\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.186\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.413\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.413\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.413\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.405\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.442\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.322\n06/28 12:52:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - segm_mAP_copypaste: 0.215 0.500 0.133 0.217 0.223 0.186\n06/28 12:52:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [3][327/327]    coco/segm_mAP: 0.2150  coco/segm_mAP_50: 0.5000  coco/segm_mAP_75: 0.1330  coco/segm_mAP_s: 0.2170  coco/segm_mAP_m: 0.2230  coco/segm_mAP_l: 0.1860  data_time: 0.0020  time: 0.0819\n06/28 12:52:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint /kaggle/working/work_dir/best_coco_segm_mAP_epoch_2.pth is removed\n06/28 12:52:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.2150 coco/segm_mAP at 3 epoch is saved to best_coco_segm_mAP_epoch_3.pth.\n06/28 12:52:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: custom_config_20230628_124315\n06/28 12:53:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 50/324]  lr: 2.0000e-02  eta: 0:17:59  time: 0.3879  data_time: 0.0447  memory: 2622  loss: 0.8606  loss_rpn_cls: 0.0934  loss_rpn_bbox: 0.0719  loss_cls: 0.1967  acc: 92.2852  loss_bbox: 0.1930  loss_mask: 0.3057\n06/28 12:53:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][100/324]  lr: 2.0000e-02  eta: 0:17:40  time: 0.3750  data_time: 0.0356  memory: 2941  loss: 0.8726  loss_rpn_cls: 0.0900  loss_rpn_bbox: 0.0717  loss_cls: 0.2060  acc: 85.0098  loss_bbox: 0.1999  loss_mask: 0.3050\n06/28 12:53:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][150/324]  lr: 2.0000e-02  eta: 0:17:22  time: 0.3842  data_time: 0.0392  memory: 3110  loss: 0.8832  loss_rpn_cls: 0.0897  loss_rpn_bbox: 0.0747  loss_cls: 0.2094  acc: 91.6504  loss_bbox: 0.2091  loss_mask: 0.3003\n06/28 12:53:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][200/324]  lr: 2.0000e-02  eta: 0:17:03  time: 0.3799  data_time: 0.0357  memory: 2820  loss: 0.8616  loss_rpn_cls: 0.0932  loss_rpn_bbox: 0.0733  loss_cls: 0.1976  acc: 91.5527  loss_bbox: 0.1943  loss_mask: 0.3032\n06/28 12:54:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][250/324]  lr: 2.0000e-02  eta: 0:16:44  time: 0.3755  data_time: 0.0361  memory: 2810  loss: 0.8458  loss_rpn_cls: 0.0791  loss_rpn_bbox: 0.0667  loss_cls: 0.1996  acc: 91.4062  loss_bbox: 0.2039  loss_mask: 0.2967\n06/28 12:54:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][300/324]  lr: 2.0000e-02  eta: 0:16:25  time: 0.3769  data_time: 0.0347  memory: 2879  loss: 0.8116  loss_rpn_cls: 0.0861  loss_rpn_bbox: 0.0677  loss_cls: 0.1825  acc: 93.2129  loss_bbox: 0.1855  loss_mask: 0.2899\n06/28 12:54:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: custom_config_20230628_124315\n06/28 12:54:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 4 epochs\n06/28 12:54:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [4][ 50/327]    eta: 0:00:20  time: 0.0728  data_time: 0.0021  memory: 2859  \n06/28 12:54:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [4][100/327]    eta: 0:00:16  time: 0.0696  data_time: 0.0017  memory: 731  \n06/28 12:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [4][150/327]    eta: 0:00:12  time: 0.0681  data_time: 0.0019  memory: 715  \n06/28 12:55:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [4][200/327]    eta: 0:00:09  time: 0.0814  data_time: 0.0034  memory: 731  \n06/28 12:55:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [4][250/327]    eta: 0:00:05  time: 0.0711  data_time: 0.0018  memory: 731  \n06/28 12:55:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [4][300/327]    eta: 0:00:01  time: 0.0706  data_time: 0.0018  memory: 702  \n06/28 12:55:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Evaluating segm...\nLoading and preparing results...\nDONE (t=0.20s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *segm*\nDONE (t=6.63s).\nAccumulating evaluation results...\nDONE (t=0.84s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.240\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.546\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.167\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.232\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.271\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.265\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.424\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.424\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.424\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.412\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.457\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.454\n06/28 12:55:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - segm_mAP_copypaste: 0.240 0.546 0.167 0.232 0.271 0.265\n06/28 12:55:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [4][327/327]    coco/segm_mAP: 0.2400  coco/segm_mAP_50: 0.5460  coco/segm_mAP_75: 0.1670  coco/segm_mAP_s: 0.2320  coco/segm_mAP_m: 0.2710  coco/segm_mAP_l: 0.2650  data_time: 0.0021  time: 0.0715\n06/28 12:55:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint /kaggle/working/work_dir/best_coco_segm_mAP_epoch_3.pth is removed\n06/28 12:55:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.2400 coco/segm_mAP at 4 epoch is saved to best_coco_segm_mAP_epoch_4.pth.\n06/28 12:55:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 50/324]  lr: 2.0000e-02  eta: 0:15:58  time: 0.3898  data_time: 0.0414  memory: 2999  loss: 0.8116  loss_rpn_cls: 0.0684  loss_rpn_bbox: 0.0622  loss_cls: 0.1934  acc: 88.4277  loss_bbox: 0.1945  loss_mask: 0.2930\n06/28 12:56:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][100/324]  lr: 2.0000e-02  eta: 0:15:40  time: 0.3800  data_time: 0.0380  memory: 3165  loss: 0.8363  loss_rpn_cls: 0.0836  loss_rpn_bbox: 0.0695  loss_cls: 0.1941  acc: 94.1895  loss_bbox: 0.1933  loss_mask: 0.2958\n06/28 12:56:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][150/324]  lr: 2.0000e-02  eta: 0:15:21  time: 0.3729  data_time: 0.0343  memory: 2768  loss: 0.7976  loss_rpn_cls: 0.0718  loss_rpn_bbox: 0.0646  loss_cls: 0.1888  acc: 94.3359  loss_bbox: 0.1879  loss_mask: 0.2845\n06/28 12:56:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][200/324]  lr: 2.0000e-02  eta: 0:15:02  time: 0.3779  data_time: 0.0347  memory: 2755  loss: 0.8414  loss_rpn_cls: 0.0785  loss_rpn_bbox: 0.0702  loss_cls: 0.1976  acc: 92.3828  loss_bbox: 0.1992  loss_mask: 0.2960\n06/28 12:56:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][250/324]  lr: 2.0000e-02  eta: 0:14:43  time: 0.3784  data_time: 0.0349  memory: 2814  loss: 0.8446  loss_rpn_cls: 0.0784  loss_rpn_bbox: 0.0701  loss_cls: 0.1978  acc: 94.6777  loss_bbox: 0.2014  loss_mask: 0.2969\n06/28 12:57:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][300/324]  lr: 2.0000e-02  eta: 0:14:25  time: 0.3827  data_time: 0.0364  memory: 2801  loss: 0.8396  loss_rpn_cls: 0.0809  loss_rpn_bbox: 0.0679  loss_cls: 0.1999  acc: 92.9688  loss_bbox: 0.1998  loss_mask: 0.2911\n06/28 12:57:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: custom_config_20230628_124315\n06/28 12:57:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 5 epochs\n06/28 12:57:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [5][ 50/327]    eta: 0:00:21  time: 0.0776  data_time: 0.0021  memory: 2908  \n06/28 12:57:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [5][100/327]    eta: 0:00:18  time: 0.0865  data_time: 0.0023  memory: 731  \n06/28 12:57:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [5][150/327]    eta: 0:00:14  time: 0.0745  data_time: 0.0018  memory: 731  \n06/28 12:57:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [5][200/327]    eta: 0:00:09  time: 0.0758  data_time: 0.0017  memory: 731  \n06/28 12:57:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [5][250/327]    eta: 0:00:06  time: 0.0807  data_time: 0.0018  memory: 731  \n06/28 12:57:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [5][300/327]    eta: 0:00:02  time: 0.0765  data_time: 0.0017  memory: 731  \n06/28 12:57:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Evaluating segm...\nLoading and preparing results...\nDONE (t=0.26s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *segm*\nDONE (t=8.05s).\nAccumulating evaluation results...\nDONE (t=0.76s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.226\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.539\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.137\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.213\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.267\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.301\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.403\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.403\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.403\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.373\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.483\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.548\n06/28 12:58:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - segm_mAP_copypaste: 0.226 0.539 0.137 0.213 0.267 0.301\n06/28 12:58:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [5][327/327]    coco/segm_mAP: 0.2260  coco/segm_mAP_50: 0.5390  coco/segm_mAP_75: 0.1370  coco/segm_mAP_s: 0.2130  coco/segm_mAP_m: 0.2670  coco/segm_mAP_l: 0.3010  data_time: 0.0019  time: 0.0777\n06/28 12:58:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 50/324]  lr: 2.0000e-02  eta: 0:13:58  time: 0.3977  data_time: 0.0434  memory: 2885  loss: 0.8294  loss_rpn_cls: 0.0681  loss_rpn_bbox: 0.0664  loss_cls: 0.1980  acc: 89.5508  loss_bbox: 0.2073  loss_mask: 0.2895\n06/28 12:58:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][100/324]  lr: 2.0000e-02  eta: 0:13:39  time: 0.3747  data_time: 0.0312  memory: 2680  loss: 0.7833  loss_rpn_cls: 0.0642  loss_rpn_bbox: 0.0625  loss_cls: 0.1796  acc: 93.9941  loss_bbox: 0.1861  loss_mask: 0.2909\n06/28 12:59:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][150/324]  lr: 2.0000e-02  eta: 0:13:20  time: 0.3750  data_time: 0.0341  memory: 2990  loss: 0.8188  loss_rpn_cls: 0.0745  loss_rpn_bbox: 0.0661  loss_cls: 0.1922  acc: 95.8496  loss_bbox: 0.1991  loss_mask: 0.2868\n06/28 12:59:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][200/324]  lr: 2.0000e-02  eta: 0:13:01  time: 0.3790  data_time: 0.0324  memory: 2875  loss: 0.7986  loss_rpn_cls: 0.0654  loss_rpn_bbox: 0.0635  loss_cls: 0.1876  acc: 90.2344  loss_bbox: 0.2003  loss_mask: 0.2817\n06/28 12:59:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][250/324]  lr: 2.0000e-02  eta: 0:12:42  time: 0.3808  data_time: 0.0372  memory: 2866  loss: 0.8237  loss_rpn_cls: 0.0740  loss_rpn_bbox: 0.0680  loss_cls: 0.1933  acc: 93.7500  loss_bbox: 0.2037  loss_mask: 0.2847\n06/28 13:00:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][300/324]  lr: 2.0000e-02  eta: 0:12:23  time: 0.3818  data_time: 0.0336  memory: 2950  loss: 0.7925  loss_rpn_cls: 0.0652  loss_rpn_bbox: 0.0623  loss_cls: 0.1831  acc: 95.6055  loss_bbox: 0.1980  loss_mask: 0.2838\n06/28 13:00:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: custom_config_20230628_124315\n06/28 13:00:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 6 epochs\n06/28 13:00:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [6][ 50/327]    eta: 0:00:20  time: 0.0743  data_time: 0.0026  memory: 2579  \n06/28 13:00:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [6][100/327]    eta: 0:00:15  time: 0.0663  data_time: 0.0018  memory: 719  \n06/28 13:00:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [6][150/327]    eta: 0:00:12  time: 0.0643  data_time: 0.0017  memory: 731  \n06/28 13:00:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [6][200/327]    eta: 0:00:08  time: 0.0649  data_time: 0.0017  memory: 731  \n06/28 13:00:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [6][250/327]    eta: 0:00:05  time: 0.0664  data_time: 0.0018  memory: 731  \n06/28 13:00:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [6][300/327]    eta: 0:00:01  time: 0.0633  data_time: 0.0017  memory: 691  \n06/28 13:00:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Evaluating segm...\nLoading and preparing results...\nDONE (t=0.17s)\ncreating index...\nindex created!\nRunning per image evaluation...\nEvaluate annotation type *segm*\nDONE (t=5.76s).\nAccumulating evaluation results...\nDONE (t=0.56s).\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.244\n Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=1000 ] = 0.556\n Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=1000 ] = 0.159\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.230\n Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.287\n Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.288\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.430\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=300 ] = 0.430\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=1000 ] = 0.430\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=1000 ] = 0.415\n Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=1000 ] = 0.470\n Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=1000 ] = 0.498\n06/28 13:00:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - segm_mAP_copypaste: 0.244 0.556 0.159 0.230 0.287 0.288\n06/28 13:00:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [6][327/327]    coco/segm_mAP: 0.2440  coco/segm_mAP_50: 0.5560  coco/segm_mAP_75: 0.1590  coco/segm_mAP_s: 0.2300  coco/segm_mAP_m: 0.2870  coco/segm_mAP_l: 0.2880  data_time: 0.0018  time: 0.0658\n06/28 13:00:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint /kaggle/working/work_dir/best_coco_segm_mAP_epoch_4.pth is removed\n06/28 13:00:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.2440 coco/segm_mAP at 6 epoch is saved to best_coco_segm_mAP_epoch_6.pth.\n06/28 13:00:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - the monitored metric did not improve in the last 2 records. best score: 0.240. \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='0.025 MB of 0.025 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3755b302300c454abfda095a432c5c22"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>▇█▇▆▅▄▅▄▃▆▇▇▅▄▆▄▅▃▅▁▅▅▄▅▃▆▆▅▆▅▃▆▇▄▆▇</td></tr><tr><td>coco/segm_mAP</td><td>▁▅▇█▇█</td></tr><tr><td>coco/segm_mAP_50</td><td>▁▅▇███</td></tr><tr><td>coco/segm_mAP_75</td><td>▁▄▆█▇█</td></tr><tr><td>coco/segm_mAP_l</td><td>▁▄▅▇██</td></tr><tr><td>coco/segm_mAP_m</td><td>▁▅▆▇▇█</td></tr><tr><td>coco/segm_mAP_s</td><td>▁▆▇█▇█</td></tr><tr><td>data_time</td><td>█▅▅▅▅▅▁▆▅▅▅▅▅▁▅▄▅▅▅▄▅▅▅▅▅▄▁▅▅▄▄▄▅▁▅▄▄▄▅▁</td></tr><tr><td>epoch</td><td>▁▁▁▁▁▁▂▂▂▂▂▂▄▄▄▄▄▄▅▅▅▅▅▅▇▇▇▇▇▇██████</td></tr><tr><td>loss</td><td>█▄▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_bbox</td><td>▁▁▂▄▅▅▆▆▆▇▇▇▇▇██▇▇▇██▇█▇▇▇▇████▇████</td></tr><tr><td>loss_cls</td><td>▇▁▃▅▅▆▆▇▇█▇▇▇▇▇▇▇▆▇▇▇▇▇▆▆▆▆▇▇▇▇▆▆▆▆▆</td></tr><tr><td>loss_mask</td><td>█▄▄▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_rpn_bbox</td><td>█▇▅▆▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▁▂▁▂▁▂▂▂▁▁▁▁▂▁</td></tr><tr><td>loss_rpn_cls</td><td>█▅▄▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr</td><td>▁▂▃▃▄▅▆▇████████████████████████████</td></tr><tr><td>memory</td><td>▁▁▂▃▄▄▄▆▄▆▅▆▅▅▅▅▅▆▅▇█▆▆▆▇█▆▅▆▆▆▅▇▆▆▇</td></tr><tr><td>time</td><td>█▆▅▅▅▅▁▆▆▅▆▅▆▁▆▆▆▆▆▆▆▆▆▆▆▆▁▆▆▆▆▆▆▁▆▆▆▆▆▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>95.60547</td></tr><tr><td>coco/segm_mAP</td><td>0.244</td></tr><tr><td>coco/segm_mAP_50</td><td>0.556</td></tr><tr><td>coco/segm_mAP_75</td><td>0.159</td></tr><tr><td>coco/segm_mAP_l</td><td>0.288</td></tr><tr><td>coco/segm_mAP_m</td><td>0.287</td></tr><tr><td>coco/segm_mAP_s</td><td>0.23</td></tr><tr><td>data_time</td><td>0.00184</td></tr><tr><td>epoch</td><td>6</td></tr><tr><td>loss</td><td>0.79246</td></tr><tr><td>loss_bbox</td><td>0.19803</td></tr><tr><td>loss_cls</td><td>0.18307</td></tr><tr><td>loss_mask</td><td>0.2838</td></tr><tr><td>loss_rpn_bbox</td><td>0.06233</td></tr><tr><td>loss_rpn_cls</td><td>0.06523</td></tr><tr><td>lr</td><td>0.02</td></tr><tr><td>memory</td><td>2950</td></tr><tr><td>time</td><td>0.06582</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">twilight-salad-30</strong> at: <a href='https://wandb.ai/ando0718/uncategorized/runs/g00ckxe1' target=\"_blank\">https://wandb.ai/ando0718/uncategorized/runs/g00ckxe1</a><br/>Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./work_dir/20230628_124315/vis_data/wandb/run-20230628_124321-g00ckxe1/logs</code>"},"metadata":{}},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"MaskRCNN(\n  (data_preprocessor): DetDataPreprocessor()\n  (backbone): ResNet(\n    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (relu): ReLU(inplace=True)\n    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n    (layer1): ResLayer(\n      (0): Bottleneck(\n        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n    )\n    (layer2): ResLayer(\n      (0): Bottleneck(\n        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (3): Bottleneck(\n        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n    )\n    (layer3): ResLayer(\n      (0): Bottleneck(\n        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (3): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (4): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (5): Bottleneck(\n        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n    )\n    (layer4): ResLayer(\n      (0): Bottleneck(\n        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (downsample): Sequential(\n          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): Bottleneck(\n        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n      (2): Bottleneck(\n        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n      )\n    )\n  )\n  init_cfg={'type': 'Pretrained', 'checkpoint': 'torchvision://resnet50'}\n  (neck): FPN(\n    (lateral_convs): ModuleList(\n      (0): ConvModule(\n        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n      )\n      (1): ConvModule(\n        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n      )\n      (2): ConvModule(\n        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n      )\n      (3): ConvModule(\n        (conv): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n      )\n    )\n    (fpn_convs): ModuleList(\n      (0-3): 4 x ConvModule(\n        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      )\n    )\n  )\n  init_cfg={'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}\n  (rpn_head): RPNHead(\n    (loss_cls): CrossEntropyLoss(avg_non_ignore=False)\n    (loss_bbox): L1Loss()\n    (rpn_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (rpn_cls): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n    (rpn_reg): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n  )\n  init_cfg={'type': 'Normal', 'layer': 'Conv2d', 'std': 0.01}\n  (roi_head): StandardRoIHead(\n    (bbox_roi_extractor): SingleRoIExtractor(\n      (roi_layers): ModuleList(\n        (0): RoIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, pool_mode=avg, aligned=True, use_torchvision=False)\n        (1): RoIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, pool_mode=avg, aligned=True, use_torchvision=False)\n        (2): RoIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, pool_mode=avg, aligned=True, use_torchvision=False)\n        (3): RoIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, pool_mode=avg, aligned=True, use_torchvision=False)\n      )\n    )\n    (bbox_head): Shared2FCBBoxHead(\n      (loss_cls): CrossEntropyLoss(avg_non_ignore=False)\n      (loss_bbox): L1Loss()\n      (fc_cls): Linear(in_features=1024, out_features=2, bias=True)\n      (fc_reg): Linear(in_features=1024, out_features=4, bias=True)\n      (shared_convs): ModuleList()\n      (shared_fcs): ModuleList(\n        (0): Linear(in_features=12544, out_features=1024, bias=True)\n        (1): Linear(in_features=1024, out_features=1024, bias=True)\n      )\n      (cls_convs): ModuleList()\n      (cls_fcs): ModuleList()\n      (reg_convs): ModuleList()\n      (reg_fcs): ModuleList()\n      (relu): ReLU(inplace=True)\n    )\n    init_cfg=[{'type': 'Normal', 'std': 0.01, 'override': {'name': 'fc_cls'}}, {'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}, {'type': 'Xavier', 'distribution': 'uniform', 'override': [{'name': 'shared_fcs'}, {'name': 'cls_fcs'}, {'name': 'reg_fcs'}]}]\n    (mask_roi_extractor): SingleRoIExtractor(\n      (roi_layers): ModuleList(\n        (0): RoIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, pool_mode=avg, aligned=True, use_torchvision=False)\n        (1): RoIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, pool_mode=avg, aligned=True, use_torchvision=False)\n        (2): RoIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, pool_mode=avg, aligned=True, use_torchvision=False)\n        (3): RoIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, pool_mode=avg, aligned=True, use_torchvision=False)\n      )\n    )\n    (mask_head): FCNMaskHead(\n      (loss_mask): CrossEntropyLoss(avg_non_ignore=False)\n      (convs): ModuleList(\n        (0-3): 4 x ConvModule(\n          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (activate): ReLU(inplace=True)\n        )\n      )\n      (upsample): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n      (conv_logits): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n      (relu): ReLU(inplace=True)\n    )\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}